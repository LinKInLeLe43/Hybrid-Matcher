_target_: src.models.MatchingModule

net:
  _target_: src.models.components.nets.loftr.LoFTRNet
  backbone:
    _target_: src.models.components.nets.loftr.ResNetFpn82
    initial_depth: 128
    layer_depths: [128, 196, 256]
  positional_encoding:
    _target_: src.models.components.nets.loftr.SinePositionalEncoding
    depth: ${model.net.backbone.layer_depths.2}
  coarse_module:
    _target_: src.models.components.nets.loftr.LoFTR
    depth: ${model.net.backbone.layer_depths.2}
    heads_count: 8
    attention:
      _target_: src.models.components.nets.loftr.LinearAttention
    types: ["self", "cross", "self", "cross", "self", "cross", "self", "cross"]
  coarse_matching:
    _target_: src.models.components.nets.loftr.CoarseMatching
    type: ???
    sparse: ???
  fine_preprocess:
    _target_: src.models.components.nets.loftr.FinePreprocess
    coarse_depth: ${model.net.backbone.layer_depths.2}
    fine_depth: ${model.net.backbone.layer_depths.0}
  fine_module:
    _target_: src.models.components.nets.loftr.LoFTR
    depth: ${model.net.backbone.layer_depths.0}
    heads_count: 8
    attention:
      _target_: src.models.components.nets.loftr.LinearAttention
    types: ["self", "cross"]
  fine_matching:
    _target_: src.models.components.nets.loftr.FineMatching

loss:
  _target_: src.models.components.losses.LoFTRLoss
  coarse_type: "${model.net.coarse_matching.type}"
  coarse_sparse: ${model.net.coarse_matching.sparse}

optimizer: ???

scheduler: ???

train_batch_size_per_gpu: ${data.train_batch_size_per_gpu}

canonical_batch_size: ???

canonical_learning_rate: ???

canonical_warmup_steps_count: ???

warmup_ratio: ???

end_point_thresholds: ???

epipolar_thresholds: ???

pose_thresholds: ???
