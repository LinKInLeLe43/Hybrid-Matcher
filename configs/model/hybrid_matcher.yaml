_target_: src.models.MatchingModule

net:
  _target_: src.models.components.nets.hybrid_matcher.HybridMatcherNet
  backbone:
    _target_: src.models.components.nets.hybrid_matcher.ResNetFpn82
    initial_depth: 128
    layer_depths: [128, 196, 256]
  local_coc:
    _target_: src.models.components.nets.hybrid_matcher.LocalCoC
    blocks_counts: [2, 2, 2]
    layer_depths: [256, 256, 256]
    hidden_depths: [256, 256, 256]
    heads_counts: [8, 8, 8]
    center_sizes: [8, 4, 2]
    fold_sizes: [1, 1, 1]
  coarse_module:
    _target_: src.models.components.nets.hybrid_matcher.GlobalCoC
    in_depth: ${model.net.local_coc.layer_depths.0}
    hidden_depth: 256
    heads_count: 8
    types: ["cross", "cross", "cross", "cross"]
    use_flow: true
    flow_depth: 128
  coarse_matching:
    _target_: src.models.components.nets.hybrid_matcher.CoarseMatching
    type: ???
    sparse: ???
    use_flow: ${model.net.coarse_module.use_flow}
    flow_decoder:
      _target_: src.models.components.nets.hybrid_matcher.FlowDecoder
      depth: 128
      radius: 8
  fine_preprocess:
    _target_: src.models.components.nets.hybrid_matcher.FinePreprocess
    coarse_depth: ${model.net.backbone.layer_depths.2}
    fine_depth: ${model.net.backbone.layer_depths.0}
  fine_module:
    _target_: src.models.components.nets.hybrid_matcher.LoFTR
    depth: ${model.net.backbone.layer_depths.0}
    heads_count: 8
    attention:
      _target_: src.models.components.nets.hybrid_matcher.FullAttention
    types: ["self", "cross"]
  fine_matching:
    _target_: src.models.components.nets.hybrid_matcher.FineMatching
  positional_encoding:
    _target_: src.models.components.nets.hybrid_matcher.SinePositionalEncoding
    depth: ${model.net.backbone.layer_depths.2}

loss:
  _target_: src.models.components.losses.LoFTRLoss
  coarse_type: "${model.net.coarse_matching.type}"
  coarse_sparse: ${model.net.coarse_matching.sparse}
  use_flow: ${model.net.coarse_module.use_flow}
  flow_weight: 0.05

optimizer: ???

scheduler: ???

train_batch_size_per_gpu: ${data.train_batch_size_per_gpu}

canonical_batch_size: ???

canonical_learning_rate: ???

canonical_warmup_step_count: ???

warmup_ratio: ???

end_point_thresholds: ???

epipolar_thresholds: ???

pose_thresholds: ???
