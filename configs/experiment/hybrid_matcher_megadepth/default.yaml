# @package _global_

defaults:
  - override /data: megadepth
  - override /model: hybrid_matcher
  - override /trainer: ddp
  - _self_

data:
  train_dataset:
    image_size: 832
    image_factor: 32
    mask_factor: 8
    center_factor: 4
  train_batch_size_per_gpu: 1
  val_dataset:
    center_factor: ${data.train_dataset.center_factor}
  test_dataset:
    image_size: 832
    center_factor: ${data.train_dataset.center_factor}

model:
  net:
    coarse_matching:
      train_percent: 0.3
  optimizer:
    _target_: torch.optim.AdamW
    _partial_: true
    weight_decay: 0.1
  scheduler:
    _target_: torch.optim.lr_scheduler.MultiStepLR
    _partial_: true
    milestones: [8, 12, 16, 20, 24]
    gamma: 0.5
  canonical_batch_size: 64
  canonical_learning_rate: 8e-3
  canonical_warmup_step_count: 1875
  warmup_ratio: 0.1
  end_point_thresholds: [1, 3, 5]
  epipolar_thresholds: [1e-4, 5e-4]
  pose_thresholds: [5, 10, 20]
