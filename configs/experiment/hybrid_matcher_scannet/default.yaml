# @package _global_

defaults:
  - override /data: scannet
  - override /model: hybrid_matcher
  - override /trainer: ddp
  - _self_

data:
  train_batch_size_per_gpu: 2

model:
  net:
    coarse_matching:
      threshold: 0.1
  optimizer:
    _target_: torch.optim.AdamW
    _partial_: true
    weight_decay: 0.1
  scheduler:
    _target_: torch.optim.lr_scheduler.MultiStepLR
    _partial_: true
    milestones: [3, 6, 9, 12, 17, 20, 23, 26, 29]
    gamma: 0.5
  canonical_batch_size: 64
  canonical_learning_rate: 6e-3
  canonical_warmup_step_count: 4800
  warmup_ratio: 0.0
  end_point_thresholds: [1, 3, 5]
  epipolar_thresholds: [5e-4, 1e-4]
  pose_thresholds: [5, 10, 20]
